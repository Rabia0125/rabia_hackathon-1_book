# Cohere API
COHERE_API_KEY="mKL0S2j2hKlAXMLjiI0GciSITw8dHUnPj4ETNm8h"

# Qdrant Cloud
QDRANT_URL="https://1723acde-eea2-42f6-9285-598424a05c0d.us-east4-0.gcp.cloud.qdrant.io:6333"
QDRANT_API_KEY="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.P8eCKaMmaUsn9TzxVfRcyxZyO5648Pfe_Y46XnJsAW8"

<<<<<<< HEAD
=======
# Google Generative AI API (Gemini)
GENENAI_API_KEY="Your GENENAI_API_KEY here"

# OpenAI API (alternative)
OPENAI_API_KEY="Your OPENAI_API_KEY here"

# AI Provider Options: "google", "openai", or "auto"
# "auto" will use Google if GENENAI_API_KEY is set, otherwise OpenAI
AI_PROVIDER=auto

# Google Model (default: gemini-1.5-flash)
GOOGLE_MODEL=gemini-1.5-flash

# OpenAI Model (default: gpt-4o-mini)
OPENAI_MODEL=gpt-4o-mini

# Mock Mode - Set to true to use simulated responses (no API quota required)
USE_MOCK=false
>>>>>>> 6e9c839 (feat: add conversation-style chat widget with message bubbles)

# Pipeline Config
TARGET_URL=https://rabia-hackathon-1-book.vercel.app
COLLECTION_NAME=physical-ai-book
CHUNK_SIZE=800
CHUNK_OVERLAP=100
BATCH_SIZE=96
